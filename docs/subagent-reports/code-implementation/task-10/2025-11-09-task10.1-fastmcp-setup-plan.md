# Task 10.1: FastMCP Server Setup - Implementation Plan

**Date**: 2025-11-09
**Session**: feat/task-10-fastmcp-integration
**Author**: Claude Code (Implementation Agent)
**Status**: IMPLEMENTATION PLAN

---

## Executive Summary

This plan details the implementation of Task 10.1: FastMCP Server Setup with the `semantic_search` tool and progressive disclosure pattern. The implementation leverages the existing, production-ready knowledge graph infrastructure (Tasks 1-7 complete, Task 9 in progress) to expose semantic search capabilities via FastMCP for Claude Desktop integration.

**Key Design Decisions**:
1. **Progressive Disclosure from Day 1**: Implement 4 response modes (`ids_only`, `metadata`, `preview`, `full`) from the start
2. **Leverage Existing Cache**: Use `HybridSearch` and `KnowledgeGraphQueryRepository` directly
3. **Type-Safe Throughout**: 100% mypy compliance with Pydantic models
4. **Start with Metadata Mode**: Default to `metadata` mode (2K-4K tokens) for optimal balance

**Success Criteria**:
- FastMCP server starts and exposes `semantic_search` tool
- 4 response modes working (ids_only, metadata, preview, full)
- <500ms P95 latency for metadata mode
- >85% test coverage
- 100% mypy compliance

---

## Architecture Overview

### System Layers

```
┌─────────────────────────────────────────────────────────────┐
│                     Claude Desktop                           │
└────────────────────┬────────────────────────────────────────┘
                     │ MCP Protocol (stdio)
                     │ semantic_search(query, top_k, response_mode)
                     ▼
┌─────────────────────────────────────────────────────────────┐
│               FastMCP Server (Task 10.1)                     │
│  ┌──────────────────────────────────────────────────────┐   │
│  │  src/mcp/server.py - FastMCP initialization          │   │
│  │  - Tool registration                                 │   │
│  │  - Logging setup                                     │   │
│  │  - Error handling                                    │   │
│  └──────────────────────────────────────────────────────┘   │
│                                                              │
│  ┌──────────────────────────────────────────────────────┐   │
│  │  src/mcp/tools/semantic_search.py                    │   │
│  │  - semantic_search() handler                         │   │
│  │  - Response mode routing                             │   │
│  │  - Result formatting                                 │   │
│  └──────────────────┬───────────────────────────────────┘   │
│                     │                                        │
│  ┌──────────────────▼───────────────────────────────────┐   │
│  │  src/mcp/models.py - Pydantic schemas                │   │
│  │  - SemanticSearchRequest                             │   │
│  │  - SemanticSearchResponse (4 variants)               │   │
│  │  - SearchResultMetadata, SearchResultPreview, etc.   │   │
│  └──────────────────────────────────────────────────────┘   │
└─────────────────────┬───────────────────────────────────────┘
                      │ Direct Python imports
                      ▼
┌─────────────────────────────────────────────────────────────┐
│        Existing Knowledge Graph (Tasks 1-7, 9)              │
│  ┌──────────────────┐  ┌──────────────────┐  ┌──────────┐  │
│  │ HybridSearch     │  │ KnowledgeGraph   │  │ Cache    │  │
│  │ - search()       │  │ QueryRepository  │  │ System   │  │
│  │ - RRF merging    │  │ - traverse_1hop  │  │          │  │
│  │ - Boosting       │  │ - get_entities   │  │          │  │
│  └──────────────────┘  └──────────────────┘  └──────────┘  │
└─────────────────────┬───────────────────────────────────────┘
                      │ psycopg connection pool
                      ▼
┌─────────────────────────────────────────────────────────────┐
│           PostgreSQL 18 + pgvector 0.8.1                    │
│  - knowledge_base (2,600 chunks, embeddings)                │
│  - knowledge_entities (entity graph)                        │
│  - entity_relationships (graph edges)                       │
└─────────────────────────────────────────────────────────────┘
```

### Key Design Principles

1. **Thin Wrapper Pattern**: FastMCP server is a thin wrapper around existing `HybridSearch` and `KnowledgeGraphQueryRepository`
2. **No Caching Duplication**: Leverage existing query cache in `HybridSearch` (no new caching layer needed for Task 10.1)
3. **Progressive Disclosure**: 4 response modes control token usage
4. **Type Safety**: Pydantic models ensure schema validation at API boundary

---

## Detailed Implementation Steps

### Step 1: Project Structure Setup (15 minutes)

**Goal**: Create directory structure and placeholder files

**Files to Create**:
```
src/mcp/
├── __init__.py                      # Package initialization
├── server.py                        # FastMCP server initialization
├── models.py                        # Pydantic schemas (request/response)
└── tools/
    ├── __init__.py                  # Tool exports
    └── semantic_search.py           # semantic_search tool handler

tests/mcp/
├── __init__.py
├── test_server.py                   # Server initialization tests
├── test_semantic_search.py          # Tool tests
└── test_models.py                   # Pydantic schema tests
```

**Commands**:
```bash
mkdir -p src/mcp/tools tests/mcp
touch src/mcp/__init__.py src/mcp/server.py src/mcp/models.py
touch src/mcp/tools/__init__.py src/mcp/tools/semantic_search.py
touch tests/mcp/__init__.py tests/mcp/test_server.py
touch tests/mcp/test_semantic_search.py tests/mcp/test_models.py
```

**Success Criteria**:
- All directories and files created
- Import structure works (`from src.mcp.server import mcp`)

---

### Step 2: Pydantic Models (45 minutes)

**Goal**: Define type-safe request/response schemas for progressive disclosure

**File**: `src/mcp/models.py`

**Models to Implement**:

#### 2.1 Request Schema

```python
from pydantic import BaseModel, Field
from typing import Literal

class SemanticSearchRequest(BaseModel):
    """Request schema for semantic_search tool.

    MCP Tool Parameters:
    - query: Search query string (required)
    - top_k: Number of results (default: 10, max: 50)
    - response_mode: Progressive disclosure level (metadata/preview/full)
    """
    query: str = Field(
        ...,
        description="Search query (natural language or keywords)",
        min_length=1,
        max_length=500
    )
    top_k: int = Field(
        default=10,
        description="Number of results to return",
        ge=1,
        le=50
    )
    response_mode: Literal["ids_only", "metadata", "preview", "full"] = Field(
        default="metadata",
        description="Response detail level: ids_only (~100 tokens), metadata (~2-4K tokens), preview (~5-10K tokens), full (~10-50K+ tokens)"
    )
```

#### 2.2 Response Schemas (Progressive Disclosure)

```python
from uuid import UUID
from typing import List, Optional

# Level 0: IDs Only (~50 tokens per result)
class SearchResultIDs(BaseModel):
    """Minimal search result with IDs and scores only."""
    chunk_id: int
    hybrid_score: float
    rank: int

# Level 1: Metadata (~100-200 tokens per result)
class SearchResultMetadata(BaseModel):
    """Search result with metadata but no content."""
    chunk_id: int
    source_file: str
    source_category: Optional[str]
    hybrid_score: float
    rank: int
    chunk_index: int
    total_chunks: int

# Level 2: Preview (~500-1000 tokens per result)
class SearchResultPreview(BaseModel):
    """Search result with metadata + snippet."""
    chunk_id: int
    source_file: str
    source_category: Optional[str]
    hybrid_score: float
    rank: int
    chunk_index: int
    total_chunks: int
    chunk_snippet: str  # First 200 chars of chunk_text
    context_header: str

# Level 3: Full (~1500+ tokens per result)
class SearchResultFull(BaseModel):
    """Full search result with all fields."""
    chunk_id: int
    chunk_text: str  # FULL TEXT (can be 1000+ tokens)
    similarity_score: float
    bm25_score: float
    hybrid_score: float
    rank: int
    score_type: str
    source_file: str
    source_category: Optional[str]
    context_header: str
    chunk_index: int
    total_chunks: int
    chunk_token_count: int

# Unified Response
class SemanticSearchResponse(BaseModel):
    """Response schema for semantic_search tool.

    Supports 4 progressive disclosure levels via response_mode:
    - ids_only: List[SearchResultIDs] (~500 tokens for 10 results)
    - metadata: List[SearchResultMetadata] (~2-4K tokens for 10 results)
    - preview: List[SearchResultPreview] (~5-10K tokens for 10 results)
    - full: List[SearchResultFull] (~15K+ tokens for 10 results)
    """
    results: List[SearchResultIDs | SearchResultMetadata | SearchResultPreview | SearchResultFull]
    total_found: int
    strategy_used: str
    execution_time_ms: float
```

**Testing Requirements**:
- Unit tests for model validation
- Test field constraints (min/max lengths, value ranges)
- Test serialization/deserialization
- Test invalid inputs raise ValidationError

**Success Criteria**:
- All models pass mypy --strict
- Pydantic validation catches invalid inputs
- Models serialize to valid JSON

---

### Step 3: FastMCP Server Initialization (30 minutes)

**Goal**: Initialize FastMCP server with logging and tool registration

**File**: `src/mcp/server.py`

**Implementation**:

```python
"""FastMCP server initialization for BMCIS Knowledge MCP.

Type-safe MCP server exposing semantic_search tool to Claude Desktop.
Supports progressive disclosure for token efficiency.
"""

from __future__ import annotations

import logging
from fastmcp import FastMCP

from src.core.config import get_settings
from src.core.database import DatabasePool
from src.core.logging import StructuredLogger
from src.search.hybrid_search import HybridSearch

# Initialize logger
logger: logging.Logger = StructuredLogger.get_logger(__name__)

# Initialize FastMCP app
mcp = FastMCP("bmcis-knowledge-mcp")

# Global state (initialized on startup)
_db_pool: DatabasePool | None = None
_hybrid_search: HybridSearch | None = None


def initialize_server() -> None:
    """Initialize server dependencies (database, search).

    Called on server startup. Initializes:
    - DatabasePool (PostgreSQL connection pool)
    - HybridSearch (vector + BM25 search with RRF)

    Raises:
        RuntimeError: If initialization fails
    """
    global _db_pool, _hybrid_search

    logger.info("Initializing BMCIS Knowledge MCP server...")

    # Load settings
    settings = get_settings()

    # Initialize database pool
    _db_pool = DatabasePool()
    logger.info("Database pool initialized")

    # Initialize hybrid search
    _hybrid_search = HybridSearch(
        db_pool=_db_pool,
        settings=settings,
        logger=logger
    )
    logger.info("HybridSearch initialized")

    logger.info("BMCIS Knowledge MCP server ready")


def get_hybrid_search() -> HybridSearch:
    """Get initialized HybridSearch instance."""
    if _hybrid_search is None:
        raise RuntimeError("Server not initialized. Call initialize_server() first.")
    return _hybrid_search


# Tool imports (register tools with FastMCP)
from src.mcp.tools.semantic_search import semantic_search

# Initialize on module load
initialize_server()
```

**Testing Requirements**:
- Test server initialization succeeds
- Test tools are registered with FastMCP
- Test database pool is created
- Test error handling for failed initialization

**Success Criteria**:
- Server starts without errors
- HybridSearch instance available
- Logging captures initialization steps

---

### Step 4: semantic_search Tool Implementation (90 minutes)

**Goal**: Implement semantic_search tool with 4 response modes

**File**: `src/mcp/tools/semantic_search.py`

**Implementation**:

```python
"""semantic_search tool implementation for FastMCP.

Hybrid semantic search combining vector similarity and BM25 keyword matching.
Supports 4 progressive disclosure modes (ids_only, metadata, preview, full).
"""

from __future__ import annotations

import time
import logging
from typing import List

from src.mcp.server import get_hybrid_search, mcp
from src.mcp.models import (
    SemanticSearchRequest,
    SemanticSearchResponse,
    SearchResultIDs,
    SearchResultMetadata,
    SearchResultPreview,
    SearchResultFull,
)
from src.search.results import SearchResult
from src.core.logging import StructuredLogger

logger: logging.Logger = StructuredLogger.get_logger(__name__)


def format_ids_only(result: SearchResult) -> SearchResultIDs:
    """Convert SearchResult to IDs-only format (Level 0)."""
    return SearchResultIDs(
        chunk_id=result.chunk_id,
        hybrid_score=result.hybrid_score,
        rank=result.rank,
    )


def format_metadata(result: SearchResult) -> SearchResultMetadata:
    """Convert SearchResult to metadata-only format (Level 1)."""
    return SearchResultMetadata(
        chunk_id=result.chunk_id,
        source_file=result.source_file,
        source_category=result.source_category,
        hybrid_score=result.hybrid_score,
        rank=result.rank,
        chunk_index=result.chunk_index,
        total_chunks=result.total_chunks,
    )


def format_preview(result: SearchResult) -> SearchResultPreview:
    """Convert SearchResult to preview format (Level 2)."""
    # Create snippet (first 200 chars)
    snippet = result.chunk_text[:200] + "..." if len(result.chunk_text) > 200 else result.chunk_text

    return SearchResultPreview(
        chunk_id=result.chunk_id,
        source_file=result.source_file,
        source_category=result.source_category,
        hybrid_score=result.hybrid_score,
        rank=result.rank,
        chunk_index=result.chunk_index,
        total_chunks=result.total_chunks,
        chunk_snippet=snippet,
        context_header=result.context_header,
    )


def format_full(result: SearchResult) -> SearchResultFull:
    """Convert SearchResult to full-content format (Level 3)."""
    return SearchResultFull(
        chunk_id=result.chunk_id,
        chunk_text=result.chunk_text,
        similarity_score=result.similarity_score,
        bm25_score=result.bm25_score,
        hybrid_score=result.hybrid_score,
        rank=result.rank,
        score_type=result.score_type,
        source_file=result.source_file,
        source_category=result.source_category,
        context_header=result.context_header,
        chunk_index=result.chunk_index,
        total_chunks=result.total_chunks,
        chunk_token_count=result.chunk_token_count,
    )


@mcp.tool()
def semantic_search(
    query: str,
    top_k: int = 10,
    response_mode: str = "metadata",
) -> SemanticSearchResponse:
    """Hybrid semantic search combining vector similarity and BM25 keyword matching.

    Args:
        query: Search query (natural language or keywords)
        top_k: Number of results to return (1-50)
        response_mode: Response detail level (ids_only/metadata/preview/full)

    Returns:
        SemanticSearchResponse with results, metadata, and timing

    Response Modes:
        - ids_only: Chunk IDs + scores only (~100 tokens for 10 results)
        - metadata: IDs + file info + scores (~2-4K tokens for 10 results)
        - preview: metadata + 200-char snippet (~5-10K tokens for 10 results)
        - full: Complete chunk content (~15K+ tokens for 10 results)

    Example:
        # Metadata-only (fast, token-efficient) - DEFAULT
        >>> semantic_search("JWT authentication", response_mode="metadata")

        # Full content (slower, more tokens)
        >>> semantic_search("JWT authentication", response_mode="full")
    """
    # Validate request
    try:
        request = SemanticSearchRequest(
            query=query,
            top_k=top_k,
            response_mode=response_mode,  # type: ignore[arg-type]
        )
    except Exception as e:
        logger.error(f"Request validation failed: {e}")
        raise ValueError(f"Invalid request parameters: {e}") from e

    # Execute search
    start_time = time.time()
    hybrid_search = get_hybrid_search()

    try:
        results: List[SearchResult] = hybrid_search.search(
            query=request.query,
            top_k=request.top_k,
            strategy="hybrid",  # Always use hybrid for MCP
            min_score=0.0,
        )
    except Exception as e:
        logger.error(f"Search execution failed: {e}")
        raise RuntimeError(f"Search failed: {e}") from e

    execution_time_ms = (time.time() - start_time) * 1000

    # Format results based on response_mode
    formatted_results: List = []
    if request.response_mode == "ids_only":
        formatted_results = [format_ids_only(r) for r in results]
    elif request.response_mode == "metadata":
        formatted_results = [format_metadata(r) for r in results]
    elif request.response_mode == "preview":
        formatted_results = [format_preview(r) for r in results]
    else:  # full
        formatted_results = [format_full(r) for r in results]

    logger.info(
        f"Search completed: {len(formatted_results)} results in {execution_time_ms:.1f}ms",
        extra={
            "query": query,
            "top_k": top_k,
            "response_mode": response_mode,
            "results_count": len(formatted_results),
            "execution_time_ms": execution_time_ms,
        }
    )

    return SemanticSearchResponse(
        results=formatted_results,  # type: ignore[arg-type]
        total_found=len(results),
        strategy_used="hybrid",
        execution_time_ms=execution_time_ms,
    )
```

**Testing Requirements**:
- Test all 4 response modes (ids_only, metadata, preview, full)
- Test parameter validation (query length, top_k range)
- Test error handling (search failures, invalid params)
- Test performance (<500ms for metadata mode)
- Test token counts per mode (estimate)

**Success Criteria**:
- Tool callable from FastMCP
- All 4 response modes return correct data
- Validation catches invalid inputs
- Performance targets met

---

### Step 5: Testing Suite (60 minutes)

**Goal**: Comprehensive test coverage >85%

**Test Files**:

#### 5.1 Model Tests (`tests/mcp/test_models.py`)

```python
"""Test Pydantic models for semantic_search tool."""

import pytest
from pydantic import ValidationError

from src.mcp.models import (
    SemanticSearchRequest,
    SemanticSearchResponse,
    SearchResultIDs,
    SearchResultMetadata,
    SearchResultPreview,
    SearchResultFull,
)


class TestSemanticSearchRequest:
    """Test request schema validation."""

    def test_valid_request_defaults(self):
        """Test valid request with default parameters."""
        req = SemanticSearchRequest(query="test query")
        assert req.query == "test query"
        assert req.top_k == 10
        assert req.response_mode == "metadata"

    def test_valid_request_all_params(self):
        """Test valid request with all parameters specified."""
        req = SemanticSearchRequest(
            query="JWT authentication",
            top_k=5,
            response_mode="full"
        )
        assert req.query == "JWT authentication"
        assert req.top_k == 5
        assert req.response_mode == "full"

    def test_invalid_query_empty(self):
        """Test empty query raises ValidationError."""
        with pytest.raises(ValidationError):
            SemanticSearchRequest(query="")

    def test_invalid_query_too_long(self):
        """Test query exceeding max length raises ValidationError."""
        with pytest.raises(ValidationError):
            SemanticSearchRequest(query="a" * 501)

    def test_invalid_top_k_too_small(self):
        """Test top_k < 1 raises ValidationError."""
        with pytest.raises(ValidationError):
            SemanticSearchRequest(query="test", top_k=0)

    def test_invalid_top_k_too_large(self):
        """Test top_k > 50 raises ValidationError."""
        with pytest.raises(ValidationError):
            SemanticSearchRequest(query="test", top_k=51)

    def test_invalid_response_mode(self):
        """Test invalid response_mode raises ValidationError."""
        with pytest.raises(ValidationError):
            SemanticSearchRequest(query="test", response_mode="invalid")


class TestSearchResultModels:
    """Test response schema models."""

    def test_search_result_ids(self):
        """Test SearchResultIDs model."""
        result = SearchResultIDs(
            chunk_id=1,
            hybrid_score=0.85,
            rank=1
        )
        assert result.chunk_id == 1
        assert result.hybrid_score == 0.85
        assert result.rank == 1

    def test_search_result_metadata(self):
        """Test SearchResultMetadata model."""
        result = SearchResultMetadata(
            chunk_id=1,
            source_file="docs/guide.md",
            source_category="guide",
            hybrid_score=0.85,
            rank=1,
            chunk_index=0,
            total_chunks=10
        )
        assert result.source_file == "docs/guide.md"
        assert result.chunk_index == 0

    def test_search_result_preview(self):
        """Test SearchResultPreview model."""
        result = SearchResultPreview(
            chunk_id=1,
            source_file="docs/guide.md",
            source_category="guide",
            hybrid_score=0.85,
            rank=1,
            chunk_index=0,
            total_chunks=10,
            chunk_snippet="This is a preview...",
            context_header="guide.md > Section 1"
        )
        assert result.chunk_snippet == "This is a preview..."
        assert result.context_header == "guide.md > Section 1"

    def test_search_result_full(self):
        """Test SearchResultFull model."""
        result = SearchResultFull(
            chunk_id=1,
            chunk_text="Full chunk content here...",
            similarity_score=0.80,
            bm25_score=0.70,
            hybrid_score=0.85,
            rank=1,
            score_type="hybrid",
            source_file="docs/guide.md",
            source_category="guide",
            context_header="guide.md > Section 1",
            chunk_index=0,
            total_chunks=10,
            chunk_token_count=512
        )
        assert result.chunk_text == "Full chunk content here..."
        assert result.chunk_token_count == 512


class TestSemanticSearchResponse:
    """Test response schema."""

    def test_response_with_metadata_results(self):
        """Test response with metadata-level results."""
        response = SemanticSearchResponse(
            results=[
                SearchResultMetadata(
                    chunk_id=1,
                    source_file="docs/guide.md",
                    source_category="guide",
                    hybrid_score=0.85,
                    rank=1,
                    chunk_index=0,
                    total_chunks=10
                )
            ],
            total_found=1,
            strategy_used="hybrid",
            execution_time_ms=250.5
        )
        assert len(response.results) == 1
        assert response.total_found == 1
        assert response.execution_time_ms == 250.5
```

#### 5.2 Tool Tests (`tests/mcp/test_semantic_search.py`)

```python
"""Test semantic_search tool implementation."""

import pytest
from src.mcp.tools.semantic_search import (
    semantic_search,
    format_ids_only,
    format_metadata,
    format_preview,
    format_full,
)
from src.search.results import SearchResult
from datetime import datetime


@pytest.fixture
def sample_search_result():
    """Create sample SearchResult for testing."""
    return SearchResult(
        chunk_id=1,
        chunk_text="This is a sample chunk about JWT authentication and security best practices.",
        similarity_score=0.85,
        bm25_score=0.75,
        hybrid_score=0.80,
        rank=1,
        score_type="hybrid",
        source_file="docs/security/auth.md",
        source_category="security",
        document_date=datetime(2024, 1, 1),
        context_header="auth.md > Security > Authentication",
        chunk_index=0,
        total_chunks=10,
        chunk_token_count=512,
        metadata={"tags": ["security", "auth"]}
    )


class TestResultFormatters:
    """Test result formatting functions."""

    def test_format_ids_only(self, sample_search_result):
        """Test IDs-only formatting."""
        result = format_ids_only(sample_search_result)
        assert result.chunk_id == 1
        assert result.hybrid_score == 0.80
        assert result.rank == 1
        # Ensure no content fields
        assert not hasattr(result, "chunk_text")

    def test_format_metadata(self, sample_search_result):
        """Test metadata formatting."""
        result = format_metadata(sample_search_result)
        assert result.chunk_id == 1
        assert result.source_file == "docs/security/auth.md"
        assert result.source_category == "security"
        assert result.hybrid_score == 0.80
        # Ensure no content fields
        assert not hasattr(result, "chunk_text")

    def test_format_preview(self, sample_search_result):
        """Test preview formatting."""
        result = format_preview(sample_search_result)
        assert result.chunk_id == 1
        assert result.source_file == "docs/security/auth.md"
        assert "JWT authentication" in result.chunk_snippet
        assert result.context_header == "auth.md > Security > Authentication"

    def test_format_full(self, sample_search_result):
        """Test full formatting."""
        result = format_full(sample_search_result)
        assert result.chunk_id == 1
        assert result.chunk_text == sample_search_result.chunk_text
        assert result.similarity_score == 0.85
        assert result.bm25_score == 0.75
        assert result.chunk_token_count == 512


@pytest.mark.skipif(True, reason="Requires running FastMCP server and database")
class TestSemanticSearchIntegration:
    """Integration tests for semantic_search tool."""

    def test_search_with_metadata_mode(self):
        """Test search with metadata response mode."""
        response = semantic_search(
            query="JWT authentication",
            top_k=5,
            response_mode="metadata"
        )
        assert response.total_found >= 0
        assert response.strategy_used == "hybrid"
        assert response.execution_time_ms > 0
        if response.results:
            assert hasattr(response.results[0], "source_file")
            assert not hasattr(response.results[0], "chunk_text")

    def test_search_with_full_mode(self):
        """Test search with full response mode."""
        response = semantic_search(
            query="authentication patterns",
            top_k=3,
            response_mode="full"
        )
        assert response.total_found >= 0
        if response.results:
            assert hasattr(response.results[0], "chunk_text")
            assert hasattr(response.results[0], "chunk_token_count")

    def test_search_with_invalid_query(self):
        """Test search with empty query raises error."""
        with pytest.raises(ValueError):
            semantic_search(query="", top_k=10)

    def test_search_with_invalid_top_k(self):
        """Test search with invalid top_k raises error."""
        with pytest.raises(ValueError):
            semantic_search(query="test", top_k=100)
```

**Success Criteria**:
- >85% coverage for all modules
- All tests pass
- Edge cases covered (empty queries, invalid params)

---

### Step 6: Type Checking & Quality Validation (15 minutes)

**Goal**: Ensure 100% mypy compliance and code quality

**Commands**:

```bash
# Type checking (strict mode)
mypy src/mcp/ --strict

# Linting
ruff check src/mcp/

# Test execution
pytest tests/mcp/ -v --cov=src/mcp --cov-report=term-missing
```

**Success Criteria**:
- No mypy errors in strict mode
- No ruff violations
- All tests pass with >85% coverage

---

## Token Budget Analysis

### Response Modes Comparison

| Mode | Fields | Tokens/Result | 10 Results | Use Case |
|------|--------|---------------|------------|----------|
| ids_only | chunk_id, score, rank | ~10 | ~100 | Quick relevance check |
| metadata | + file, category, index | ~100-200 | ~2-4K | File identification |
| preview | + 200-char snippet | ~500-1000 | ~5-10K | Content preview |
| full | + full text (1000+ tokens) | ~1500+ | ~15K+ | Deep analysis |

### Token Reduction Example

**Query**: "JWT authentication best practices"

**Traditional Approach (Full)**:
- 10 results × 1,500 tokens = **15,000 tokens**

**Progressive Disclosure**:
- Step 1: metadata mode (10 results) = 2,000 tokens
- Step 2: User selects top 3 → full mode (3 results) = 4,500 tokens
- **Total: 6,500 tokens (57% reduction)**

---

## Performance Targets

| Metric | Target | Measurement |
|--------|--------|-------------|
| Metadata mode P50 | <200ms | `execution_time_ms` in response |
| Metadata mode P95 | <500ms | Performance tests |
| Full mode P50 | <300ms | `execution_time_ms` in response |
| Full mode P95 | <800ms | Performance tests |
| Server startup | <5 seconds | Time to first request |

---

## Risk Mitigation

### Risk 1: FastMCP Integration Complexity
**Mitigation**: Start with minimal server (just `semantic_search`), no auth, no advanced features

### Risk 2: Performance Regression
**Mitigation**: Leverage existing `HybridSearch` cache, no new layers

### Risk 3: Type Safety Issues
**Mitigation**: Run mypy --strict throughout development

### Risk 4: Test Coverage Gaps
**Mitigation**: Write tests alongside implementation (not after)

---

## Implementation Timeline

### Phase 1: Setup (30 minutes)
- ✅ Create directory structure
- ✅ Create placeholder files
- ✅ Verify imports work

### Phase 2: Models (45 minutes)
- ✅ Define request schema
- ✅ Define 4 response schemas
- ✅ Write model tests

### Phase 3: Server (30 minutes)
- ✅ Initialize FastMCP
- ✅ Setup database pool
- ✅ Setup HybridSearch
- ✅ Write server tests

### Phase 4: Tool (90 minutes)
- ✅ Implement semantic_search handler
- ✅ Implement 4 format functions
- ✅ Write tool tests

### Phase 5: Quality (30 minutes)
- ✅ Run mypy --strict
- ✅ Run ruff
- ✅ Run tests with coverage
- ✅ Fix any issues

**Total Estimated Time**: ~3.5 hours

---

## Success Metrics

### Functional
- [ ] FastMCP server starts successfully
- [ ] `semantic_search` tool registers
- [ ] All 4 response modes work correctly
- [ ] Pydantic validation works
- [ ] Error handling comprehensive

### Performance
- [ ] Metadata mode <500ms P95
- [ ] Full mode <800ms P95
- [ ] No performance regression vs direct `HybridSearch.search()`

### Quality
- [ ] 100% mypy compliance (strict mode)
- [ ] >85% test coverage
- [ ] All tests pass
- [ ] No ruff violations

---

## Next Steps (Task 10.2)

After completing Task 10.1, the following enhancements are planned for Task 10.2:

1. **Add `find_vendor_info` tool**: Entity-centric search using `KnowledgeGraphQueryRepository`
2. **Add authentication**: API key validation
3. **Add rate limiting**: Per-key request limits
4. **Add response caching**: Cache responses for repeated queries
5. **Add monitoring**: Request logging and metrics

---

## References

- **FastMCP Documentation**: https://github.com/jlowin/fastmcp
- **Implementation Plan**: docs/subagent-reports/code-implementation/task-10/2025-11-09-1449-task10-implementation-plan.md
- **Security Analysis**: docs/subagent-reports/security-analysis/task-10/2025-11-09-1450-task10-security-analysis.md
- **HybridSearch**: src/search/hybrid_search.py
- **SearchResult**: src/search/results.py
- **KnowledgeGraph**: src/knowledge_graph/query_repository.py

---

**Document Version**: 1.0
**Last Updated**: 2025-11-09
**Status**: READY FOR IMPLEMENTATION

Generated with Claude Code
Co-Authored-By: Claude <noreply@anthropic.com>
