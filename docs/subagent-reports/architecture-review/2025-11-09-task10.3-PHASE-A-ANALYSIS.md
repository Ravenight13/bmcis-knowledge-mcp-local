# Task 10.3 Phase A: Architecture Analysis & Design Document

**Date**: 2025-11-09
**Task**: 10.3 - Response Formatting & Tiered Caching
**Phase**: A - Architecture & Analysis
**Status**: COMPLETE ✅

---

## Executive Summary

Task 10.3 adds intelligent caching, pagination, and response filtering to MCP tools that already have excellent progressive disclosure models. Current state: both semantic_search and find_vendor_info already support 4-tier progressive disclosure (ids_only, metadata, preview, full) with 90%+ token reduction. Task 10.3 focuses on:

1. **Add caching layer** (in-memory with TTL + LRU eviction)
2. **Implement pagination** (cursor-based with configurable page size)
3. **Add response filtering** (field-level selection)

Token efficiency will improve from 90%+ to 95%+ reduction through caching of repeated queries.

---

## Current Architecture Analysis

### 1. Progressive Disclosure Status ✅ (Already Complete)

#### semantic_search Tool
```
Implementation: src/mcp/tools/semantic_search.py (284 LOC)
Response Modes: 4 tiers implemented (lines 259-266)
  ├── ids_only: SearchResultIDs (chunk_id + score + rank) = ~100 tokens/10 results
  ├── metadata: SearchResultMetadata (ids + file info) = ~2-4K tokens/10 results
  ├── preview: SearchResultPreview (metadata + 200-char snippet) = ~5-10K tokens/10 results
  └── full: SearchResultFull (complete chunk content) = ~15-50K tokens/10 results

Request Handling: SemanticSearchRequest (Pydantic v2)
  ├── query: str (1-500 chars, validated)
  ├── top_k: int (1-50, default 10)
  └── response_mode: Literal["ids_only", "metadata", "preview", "full"]

Response Format: SemanticSearchResponse
  ├── results: Union[List[SearchResultIDs], List[SearchResultMetadata], List[SearchResultPreview], List[SearchResultFull]]
  ├── total_found: int
  ├── strategy_used: str ("hybrid")
  └── execution_time_ms: float

Performance:
  - Metadata mode: <200ms P50, <500ms P95
  - Full mode: <300ms P50, <800ms P95
  - Uses existing HybridSearch cache
```

#### find_vendor_info Tool
```
Implementation: src/mcp/tools/find_vendor_info.py (495 LOC)
Response Modes: 4 tiers implemented
  ├── ids_only: VendorInfoIDs (vendor_id + counts) = ~100-500 tokens
  ├── metadata: VendorInfoMetadata (ids + statistics) = ~2-4K tokens
  ├── preview: VendorInfoPreview (metadata + top 5 entities/relationships) = ~5-10K tokens
  └── full: VendorInfoFull (complete graph, max 100 entities, 500 relationships) = ~10-50K+ tokens

Request Handling: FindVendorInfoRequest (Pydantic v2)
  ├── vendor_name: str (1-200 chars, normalized)
  └── response_mode: Literal["ids_only", "metadata", "preview", "full"]

Response Format: FindVendorInfoResponse
  ├── vendor_id: UUID
  ├── vendor_name: str
  ├── results: Union[VendorInfoIDs, VendorInfoMetadata, VendorInfoPreview, VendorInfoFull]
  ├── total_entities: int
  ├── total_relationships: int
  └── execution_time_ms: float

Performance:
  - Metadata mode: ~195ms P95
  - Full mode: ~1,287ms P95
  - No existing caching (opportunity for improvement)
```

### 2. Current Architecture Gaps ❌

#### A. No Caching Layer
```
Problem:
  - Identical queries execute fresh search every time
  - Repeated "semantic_search('authentication')" = repeated vector DB queries
  - No deduplication of expensive find_vendor_info() calls
  - Wasted computation in high-volume scenarios

Impact:
  - 50%+ of queries likely duplicates in real usage
  - P95 latency unnecessarily high for repeated queries
  - Database load scales linearly with request volume

Opportunity:
  - 80%+ cache hit rate achievable in realistic Claude Desktop usage
  - Easy <100ms latency for cached results
  - Massive cost reduction (fewer vector DB queries)
```

#### B. No Pagination Support
```
Current Behavior:
  - top_k parameter limits results upfront (1-50 max)
  - Can't iterate through large result sets
  - If user wants results 11-20, must issue new query

Limitation:
  - User can't efficiently browse paginated results
  - Requires fetching all data upfront or running new queries
  - Wastes tokens on results user doesn't need

Opportunity:
  - Add cursor-based pagination (offset is vulnerable)
  - Support "get more results" workflow
  - Token efficiency: return only what user needs per page
```

#### C. No Response Filtering
```
Current Behavior:
  - Users get full response structure even if they need subset of fields
  - No ability to select specific fields to reduce token count

Example:
  User only wants chunk_id + score (for deduplication)
  But gets full: chunk_id, score, rank, source_file, source_category, context_header, etc.

Opportunity:
  - Add field-level filtering (select specific fields)
  - Reduce token count beyond progressive disclosure
  - Example: metadata with only ID + score = ~30 tokens instead of ~200
```

---

## Proposed Architecture

### 1. Cache Layer Design

```
CacheLayer (new: src/mcp/cache.py)
├── Interface:
│   ├── get(cache_key: str) -> Optional[Any]
│   ├── set(cache_key: str, value: Any, ttl_seconds: int = 300)
│   ├── delete(cache_key: str)
│   ├── clear()
│   └── get_stats() -> CacheStats
│
├── Implementation: Thread-safe in-memory dictionary
│   ├── Data structure: Dict[str, CacheEntry]
│   ├── CacheEntry: (value, created_at, ttl_seconds)
│   ├── Eviction: LRU + TTL-based
│   └── Max size: 1,000 entries (configurable)
│
├── Configuration:
│   ├── max_entries: 1,000
│   ├── default_ttl: 300 seconds (5 minutes)
│   ├── semantic_search_ttl: 30 seconds (queries change frequently)
│   ├── vendor_info_ttl: 300 seconds (relatively static)
│   └── enable_metrics: True
│
└── Integration:
    ├── semantic_search: Check cache before search, cache results for 30s
    ├── find_vendor_info: Check cache before query, cache results for 300s
    └── Cache keys: hash(query_params) for deterministic lookup

CacheStats (metrics):
├── hits: int
├── misses: int
├── evictions: int
├── current_size: int
├── memory_usage_bytes: int
└── hit_rate: float (hits / (hits + misses))
```

### 2. Pagination Design

```
PaginatedResponse (new model)
├── results: List[T] (current page results)
├── cursor: Optional[str] (for next page, null if last page)
├── total_available: int (total results matching query)
├── page_size: int (results per page)
├── has_more: bool (true if more results available)
└── returned_count: int (actual results in this page)

PaginationRequest (extend existing requests)
├── top_k: int (remove or deprecate, replaced with page_size)
├── page_size: int = 10 (NEW - results per page)
├── cursor: Optional[str] = None (NEW - pagination token)

Implementation Strategy:
├── Keep top_k for backward compatibility
├── If top_k provided: use as page_size
├── If both: top_k takes precedence (legacy support)
├── Cursor format: base64(encoded_state) where state includes query hash + offset
└── Stability: cursors tied to exact query (sort order deterministic)

CursorFormat:
├── Encoding: base64(json.dumps({
│   "query_hash": sha256(query),
│   "offset": int,
│   "response_mode": str
│ }))
├── Security: hash prevents tampering
└── Expiry: cursors tied to cache TTL (implicit expiration)
```

### 3. Response Filtering Design

```
FilteredResponse (optional feature)
├── Usage: Add "fields" parameter to request (optional, backward compatible)
├── Example: semantic_search(query, fields=["chunk_id", "score"])
├── Returns: Stripped response with only selected fields

FieldSelection Strategy:
├── White-list approach (only allow specified fields)
├── If fields parameter omitted: return all (current behavior)
├── Schema validation: ensure fields exist in response model
├── Type preservation: returned types unchanged

Common Field Combos (for reference):
├── Deduplication: ["chunk_id", "score"]
├── Quick summary: ["chunk_id", "score", "source_file"]
├── Full analysis: all fields (default)
└── Minimal: ["chunk_id"] (just IDs)
```

---

## Data Flow Architecture

### Current (Without Caching)
```
User Query
    ↓
validate_request(Pydantic)
    ↓
execute_search()  ← Always hits database
    ↓
format_results()
    ↓
Return Response
```

### Proposed (With Caching + Pagination + Filtering)
```
User Query
    ↓
validate_request(Pydantic)
    ↓
compute_cache_key(query)
    ↓
cache.get(cache_key)  ← NEW: Check cache first
    ├─ HIT: format_for_pagination() → filter_fields() → Return
    └─ MISS:
        ↓
        execute_search()  ← Database query
        ↓
        cache.set(cache_key, results)  ← NEW: Store for next time
        ↓
        format_for_pagination()  ← NEW: Add cursor/page info
        ↓
        filter_fields()  ← NEW: Apply field selection
        ↓
        Return Response
```

---

## Implementation Breakdown (By Subagent)

### Phase B: Extend semantic_search Models (fastapi-pro + pydantic-specialist)
**Files to create/modify**:
- `src/mcp/models.py`: Add pagination + filtering models
- New fields in SemanticSearchRequest: page_size, cursor, fields

**Tasks**:
- Add PaginationMetadata model
- Extend SemanticSearchRequest with pagination + filtering fields
- Add field validation (white-list)
- Write 50+ validation tests

### Phase C: Implement Cache Layer (python-wizard)
**Files to create**:
- `src/mcp/cache.py`: CacheLayer class (100-150 LOC)
- `tests/mcp/test_cache.py`: Cache unit tests (200-300 LOC)

**Tasks**:
- Implement thread-safe in-memory cache
- LRU eviction + TTL expiration
- Cache statistics tracking
- Integration tests with both tools

### Phase D: Pagination & Filtering (fastapi-pro)
**Files to modify**:
- `src/mcp/tools/semantic_search.py`: Add pagination logic
- `src/mcp/tools/find_vendor_info.py`: Add pagination logic

**Tasks**:
- Implement cursor-based pagination
- Add field filtering logic
- Integrate with cache layer
- 40+ pagination/filter tests

### Phase E: Testing & Performance (test-automator)
**Files to create/modify**:
- `tests/mcp/test_integration_cache.py`: Cache integration tests
- Performance benchmarks

**Tasks**:
- Full integration tests for all features
- Cache hit rate benchmarks
- Token efficiency validation
- Performance regression tests

### Phase F: Documentation (docs-architect)
**Files to create**:
- `docs/guides/caching-configuration.md`: Cache setup + tuning
- `docs/api-reference/` updates: Add pagination + filtering examples
- `docs/performance/cache-performance-report.md`: Benchmarks

---

## Key Design Decisions

### 1. In-Memory Cache vs Redis
**Decision**: In-memory cache (Python dict with TTL)

**Rationale**:
- MCP server is single-process per Claude Desktop instance
- No cross-process caching needed
- Simpler, zero dependencies, faster
- 1,000 entries = ~10-50MB memory (negligible)
- TTL ensures automatic cleanup

**Future**: Could upgrade to Redis if multi-instance deployment needed

### 2. Cursor-Based vs Offset Pagination
**Decision**: Cursor-based pagination

**Rationale**:
- Stable (offset fails if data changes between requests)
- Efficient (don't need to skip results)
- Works well with caching
- Industry standard for APIs

### 3. Field Filtering Approach
**Decision**: Optional white-list parameter (backward compatible)

**Rationale**:
- Backward compatible (omit parameter = old behavior)
- Explicit (white-list safer than blacklist)
- Simple implementation (2-3 LOC per response)
- Users opt-in (no breaking changes)

---

## Success Criteria (Task 10.3 Complete)

✅ **Caching Layer**:
- [ ] CacheLayer class with get/set/delete/clear operations
- [ ] LRU eviction for 1,000-entry max
- [ ] TTL-based expiration (30s for search, 300s for vendor data)
- [ ] Cache statistics (hits, misses, evictions)
- [ ] Thread-safe operations

✅ **Pagination Support**:
- [ ] Cursor-based pagination implemented
- [ ] cursor parameter in responses
- [ ] has_more flag for user feedback
- [ ] Backward compatible with top_k parameter
- [ ] Stable cursors (same query = same order)

✅ **Response Filtering**:
- [ ] Optional fields parameter
- [ ] White-list field validation
- [ ] Works with all response modes
- [ ] Backward compatible (omitted = all fields)

✅ **Testing**:
- [ ] 50+ model validation tests
- [ ] 30+ cache layer tests
- [ ] 40+ pagination/filter tests
- [ ] 30+ integration tests
- [ ] Total: 350+ tests all passing

✅ **Performance**:
- [ ] Cache hit rate: 80%+ in realistic usage
- [ ] Cached result latency: <100ms P95
- [ ] Token efficiency: 95%+ reduction (ids_only mode)
- [ ] No performance regression for uncached queries

✅ **Documentation**:
- [ ] Cache configuration guide
- [ ] Pagination examples
- [ ] Field filtering examples
- [ ] Performance comparison (before/after caching)

---

## File Organization

```
Task 10.3 Deliverables:
├── src/mcp/
│   ├── cache.py (NEW - 100-150 LOC)
│   ├── models.py (MODIFIED - add pagination models)
│   ├── tools/
│   │   ├── semantic_search.py (MODIFIED - integrate cache + pagination)
│   │   └── find_vendor_info.py (MODIFIED - integrate cache + pagination)
│   └── server.py (MODIFIED - register cache instance)
│
├── tests/mcp/
│   ├── test_cache.py (NEW - 200-300 LOC)
│   ├── test_models.py (MODIFIED - add pagination tests)
│   ├── test_semantic_search.py (MODIFIED - add cache + pagination tests)
│   ├── test_find_vendor_info.py (MODIFIED - add cache + pagination tests)
│   └── test_integration_cache.py (NEW - 150-200 LOC)
│
├── docs/
│   ├── guides/
│   │   ├── caching-configuration.md (NEW)
│   │   └── mcp-usage-examples.md (MODIFIED - add pagination examples)
│   ├── api-reference/
│   │   └── mcp-tools.md (MODIFIED - document cache behavior)
│   └── performance/
│       └── cache-performance-report.md (NEW)
│
└── docs/subagent-reports/
    └── architecture-review/
        └── 2025-11-09-task10.3-PHASE-A-ANALYSIS.md (THIS FILE)
```

---

## Risk Assessment & Mitigation

### Risk 1: Cache Invalidation
**Issue**: Stale cache data if knowledge graph updates

**Mitigation**:
- Short TTL (30s for search queries, 300s for vendor data)
- Manual invalidation API (for development)
- Metrics tracking (cache hit rate monitoring)

### Risk 2: Memory Growth
**Issue**: Cache grows unbounded if entries don't expire

**Mitigation**:
- Max 1,000 entries (hard limit)
- LRU eviction removes oldest unused entries
- TTL-based cleanup on every access
- Memory monitoring in stats

### Risk 3: Cursor Stability
**Issue**: Cursor becomes invalid if query result order changes

**Mitigation**:
- Hash-based cursor (tied to exact query)
- Consistent sorting in results
- Cursor expiration (same as cache TTL)
- Test suite validates cursor across multiple pages

---

## Next Steps (For Subagents)

Phase A Complete ✅

**Phase B (fastapi-pro + pydantic-specialist)**:
1. Extend SemanticSearchRequest with pagination + filtering
2. Create PaginationMetadata model
3. Add 50+ validation tests
4. Validate with mypy --strict

**Phase C (python-wizard)**:
1. Implement src/mcp/cache.py
2. Create cache tests with TTL + LRU validation
3. Integration tests with both tools

**Phase D (fastapi-pro)**:
1. Integrate cache into semantic_search
2. Integrate cache into find_vendor_info
3. Implement pagination logic
4. Implement field filtering

**Phase E (test-automator)**:
1. 30+ integration tests for full feature
2. Performance benchmarks
3. Token efficiency validation
4. Run full test suite (350+)

**Phase F (docs-architect)**:
1. Cache configuration guide
2. Pagination + filtering examples
3. Performance comparison report
4. API reference updates

---

## Estimated Timeline

- Phase B: 1.5-2 hours
- Phase C: 1.5-2 hours
- Phase D: 1.5-2 hours
- Phase E: 1-1.5 hours
- Phase F: 1-1.5 hours
- **Total: 7-9 hours** (within 8-10 hour target)

Parallel execution (B+C+D simultaneously): **2.5-3 hours wall time**

---

**Analysis Complete** ✅

Generated by Phase A - Architecture & Analysis
Ready for parallel subagent execution (Phases B-F)
